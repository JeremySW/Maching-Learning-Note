# -*- coding: utf-8 -*-
"""Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Aa7Xq16En1ac5aZYy0oHc8lomGrxgHFB
"""

# Commented out IPython magic to ensure Python compatibility.
# 导入tensorflow 2.1版本（系统默认为1.5）
# %tensorflow_version 2.x

# 导入tensorflow包，检查版本
import tensorflow as tf
print(tf.__version__)

# 获取mnist数据集
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 导入matplotlib包
import matplotlib.pyplot as plt

# 打印其中一个训练数据
image_index = 1234
print(y_train[image_index])
plt.imshow(x_train[image_index])
plt.show()

import numpy as np
# 数据规整化
def reset_data_for_lenet(data):
  reset_data = np.pad(data, ((0, 0), (2, 2), (2, 2)), 'constant', constant_values=0)
  reset_data = reset_data.astype('float32')
  reset_data = reset_data/255
  # reset_data = reset_data.reshape(reset_data.shape[0], 32, 32, 1)
  return reset_data

x_train = reset_data_for_lenet(x_train)
x_train = x_train.reshape(x_train.shape[0], 32, 32, 1)
x_test = reset_data_for_lenet(x_test)
x_test = x_test.reshape(x_test.shape[0], 32, 32, 1)

print(x_train.shape, x_test.shape)

# 建立模型
model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(filters=6, kernel_size=(5,5), padding='valid', activation=tf.nn.relu, input_shape=(32, 32, 1)),
  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),
  tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5), padding='valid', activation=tf.nn.tanh),
  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),
  tf.keras.layers.Conv2D(filters=120, kernel_size=(5,5), strides=(1,1), padding='valid', activation=tf.nn.tanh),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(units=84, activation=tf.nn.tanh),
  tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)
])

model.summary()

# 超参数设置：训练轮数、批大小、学习率
epoch = 12 # 训练轮数
batch_size = 64 # 一次训练所选取的样本数（批大小）
learning_rate = 0.001

adam_optimizer = tf.keras.optimizers.Adam(learning_rate)
model.compile(optimizer=adam_optimizer, 
              loss=tf.keras.losses.sparse_categorical_crossentropy,
              metrics=['accuracy'])

# 开始训练
import datetime
start_time = datetime.datetime.now()

model.fit(x=x_train,
          y=y_train,
          batch_size=batch_size,
          epochs=epoch)

end_time = datetime.datetime.now()
training_time = end_time - start_time
print("time cost: ",training_time)

from google.colab import drive
drive.mount('/gdrive')

model.save('/gdrive/My Drive/AI/model/lenet_model.h5')

# 评估指标
print(model.evaluate(x_test, y_test))

# 预测
image_index = np.random.randint(0,9999)
print(x_test[image_index].shape)

plt.imshow(x_test[image_index].reshape(32,32))
plt.show()

# 使用模型进行预测
pred = model.predict(x_test[image_index].reshape(1, 32, 32, 1))
print(pred)
print(pred.argmax())